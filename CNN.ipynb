{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.python.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.python.keras.utils import to_categorical\n",
    "from tensorflow.python.keras.models import model_from_json\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving images to validation folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b_path = '/home/nikita/Roman_Num/New_data/Train/'\n",
    "# list_classes = os.listdir('/home/nikita/Roman_Num/New_data/Train/')\n",
    "# # count_el = 0\n",
    "# for class_name in list_classes:\n",
    "#     count_el = 0\n",
    "# #     print(class_name)\n",
    "#     for element in os.listdir(b_path + class_name + '/'):\n",
    "#         if not os.path.exists(\"/home/nikita/Roman_Num/New_data/Validation/\" + class_name):\n",
    "#             os.makedirs(\"/home/nikita/Roman_Num/New_data/Validation/\" + class_name)\n",
    "# #         print(element)\n",
    "#         if count_el < 50:\n",
    "#             print(\"mv\", b_path + class_name + '/' + element, \"/home/nikita/Roman_Num/New_data/Validation/\" + class_name + '/')\n",
    "#             subprocess.call([\"mv\", b_path + class_name + '/' + element, \"/home/nikita/Roman_Num/New_data/Validation/\" + class_name + '/'])\n",
    "#             count_el +=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_elements(status):\n",
    "    counter = 0\n",
    "    if status == \"Train\":\n",
    "        base_path = \"/home/nikita/Roman_Num/New_data/Train/\"\n",
    "    if status == \"Val\":\n",
    "        base_path = \"/home/nikita/Roman_Num/New_data/Validation/\"\n",
    "    if status == \"Test\":\n",
    "        base_path = \"/home/nikita/Roman_Num/New_data/Test/\"\n",
    "    for class_ in os.listdir(base_path):\n",
    "        count_el = len(os.listdir(base_path + class_))\n",
    "        counter+=count_el\n",
    "    print(\"Samples for {0}: {1}\".format(base_path, counter))\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples for /home/nikita/Roman_Num/New_data/Train/: 6512\n",
      "Samples for /home/nikita/Roman_Num/New_data/Validation/: 400\n",
      "Samples for /home/nikita/Roman_Num/New_data/Test/: 1680\n",
      "Found 6512 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir = '/home/nikita/Roman_Num/New_data/Train'\n",
    "\n",
    "val_dir = '/home/nikita/Roman_Num/New_data/Validation'\n",
    "\n",
    "test_dir = '/home/nikita/Roman_Num/New_data/Test'\n",
    "\n",
    "img_width, img_height = 28, 28\n",
    "input_shape = (img_width, img_height, 3)\n",
    "\n",
    "epochs = 30\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "nb_train_samples = get_count_elements(status=\"Train\")\n",
    "nb_validation_samples = get_count_elements(status=\"Val\")\n",
    "nb_test_samples = get_count_elements(status=\"Test\")\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(8))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1680 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "407/407 [==============================] - 62s 153ms/step - loss: 1.5046 - acc: 0.4796 - val_loss: 0.3806 - val_acc: 0.8975\n",
      "Epoch 2/30\n",
      "407/407 [==============================] - 12s 30ms/step - loss: 0.2622 - acc: 0.9261 - val_loss: 0.0276 - val_acc: 0.9925\n",
      "Epoch 3/30\n",
      "407/407 [==============================] - 12s 29ms/step - loss: 0.1065 - acc: 0.9693 - val_loss: 0.0235 - val_acc: 0.9950\n",
      "Epoch 4/30\n",
      "407/407 [==============================] - 11s 26ms/step - loss: 0.0592 - acc: 0.9845 - val_loss: 0.0146 - val_acc: 0.9975\n",
      "Epoch 5/30\n",
      "407/407 [==============================] - 10s 26ms/step - loss: 0.0490 - acc: 0.9873 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 6/30\n",
      "407/407 [==============================] - 10s 26ms/step - loss: 0.0366 - acc: 0.9896 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 7/30\n",
      "407/407 [==============================] - 11s 27ms/step - loss: 0.0349 - acc: 0.9899 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 8/30\n",
      "407/407 [==============================] - 10s 26ms/step - loss: 0.0251 - acc: 0.9934 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 9/30\n",
      "407/407 [==============================] - 10s 26ms/step - loss: 0.0242 - acc: 0.9920 - val_loss: 0.0019 - val_acc: 0.9975\n",
      "Epoch 10/30\n",
      "407/407 [==============================] - 11s 26ms/step - loss: 0.0207 - acc: 0.9940 - val_loss: 5.4028e-04 - val_acc: 1.0000\n",
      "Epoch 11/30\n",
      "407/407 [==============================] - 10s 26ms/step - loss: 0.0195 - acc: 0.9939 - val_loss: 5.2005e-04 - val_acc: 1.0000\n",
      "Epoch 12/30\n",
      "407/407 [==============================] - 10s 25ms/step - loss: 0.0178 - acc: 0.9936 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 13/30\n",
      "407/407 [==============================] - 13s 31ms/step - loss: 0.0266 - acc: 0.9923 - val_loss: 2.2306e-04 - val_acc: 1.0000\n",
      "Epoch 14/30\n",
      "407/407 [==============================] - 13s 33ms/step - loss: 0.0136 - acc: 0.9968 - val_loss: 9.6440e-05 - val_acc: 1.0000\n",
      "Epoch 15/30\n",
      "407/407 [==============================] - 14s 35ms/step - loss: 0.0177 - acc: 0.9946 - val_loss: 4.3676e-04 - val_acc: 1.0000\n",
      "Epoch 16/30\n",
      "407/407 [==============================] - 11s 26ms/step - loss: 0.0162 - acc: 0.9949 - val_loss: 1.5199e-04 - val_acc: 1.0000\n",
      "Epoch 17/30\n",
      "407/407 [==============================] - 11s 26ms/step - loss: 0.0117 - acc: 0.9968 - val_loss: 2.4803e-04 - val_acc: 1.0000\n",
      "Epoch 18/30\n",
      "407/407 [==============================] - 11s 27ms/step - loss: 0.0109 - acc: 0.9966 - val_loss: 2.8608e-04 - val_acc: 1.0000\n",
      "Epoch 19/30\n",
      "407/407 [==============================] - 11s 26ms/step - loss: 0.0120 - acc: 0.9963 - val_loss: 8.2157e-05 - val_acc: 1.0000\n",
      "Epoch 20/30\n",
      "407/407 [==============================] - 11s 26ms/step - loss: 0.0100 - acc: 0.9965 - val_loss: 5.0260e-05 - val_acc: 1.0000\n",
      "Epoch 21/30\n",
      "407/407 [==============================] - 12s 30ms/step - loss: 0.0083 - acc: 0.9969 - val_loss: 4.9388e-05 - val_acc: 1.0000\n",
      "Epoch 22/30\n",
      "407/407 [==============================] - 14s 34ms/step - loss: 0.0087 - acc: 0.9971 - val_loss: 3.3624e-04 - val_acc: 1.0000\n",
      "Epoch 23/30\n",
      "407/407 [==============================] - 11s 27ms/step - loss: 0.0084 - acc: 0.9966 - val_loss: 5.9446e-04 - val_acc: 1.0000\n",
      "Epoch 24/30\n",
      "407/407 [==============================] - 11s 26ms/step - loss: 0.0076 - acc: 0.9980 - val_loss: 6.9000e-05 - val_acc: 1.0000\n",
      "Epoch 25/30\n",
      "407/407 [==============================] - 12s 30ms/step - loss: 0.0067 - acc: 0.9980 - val_loss: 2.0473e-05 - val_acc: 1.0000\n",
      "Epoch 26/30\n",
      "407/407 [==============================] - 12s 30ms/step - loss: 0.0087 - acc: 0.9972 - val_loss: 1.1578e-04 - val_acc: 1.0000\n",
      "Epoch 27/30\n",
      "407/407 [==============================] - 12s 30ms/step - loss: 0.0094 - acc: 0.9966 - val_loss: 2.0955e-04 - val_acc: 1.0000\n",
      "Epoch 28/30\n",
      "407/407 [==============================] - 12s 30ms/step - loss: 0.0077 - acc: 0.9977 - val_loss: 8.8444e-05 - val_acc: 1.0000\n",
      "Epoch 29/30\n",
      "407/407 [==============================] - 12s 30ms/step - loss: 0.0079 - acc: 0.9977 - val_loss: 1.5763e-05 - val_acc: 1.0000\n",
      "Epoch 30/30\n",
      "407/407 [==============================] - 12s 30ms/step - loss: 0.0076 - acc: 0.9972 - val_loss: 6.0931e-05 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f512c35a908>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Аккуратность на тестовых данных: 99.94%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate_generator(test_generator, nb_test_samples // batch_size)\n",
    "print(\"Аккуратность на тестовых данных: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "# Записываем модель в файл\n",
    "json_file = open(\"mnist_model.json\", \"w\")\n",
    "json_file.write(model_json)\n",
    "json_file.close()\n",
    "\n",
    "model_yaml = model.to_yaml()\n",
    "yaml_file = open(\"mnist_model.yml\", \"w\")\n",
    "# Записываем модель в файл\n",
    "yaml_file.write(model_yaml)\n",
    "yaml_file.close()\n",
    "model.save_weights(\"mnist_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели на тестовых данных: 99.94%\n"
     ]
    }
   ],
   "source": [
    "json_file = open(\"mnist_model.json\", \"r\")\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "# Создаем модель на основе загруженных данных\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# Загружаем веса в модель\n",
    "loaded_model.load_weights(\"mnist_model.h5\")\n",
    "loaded_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])\n",
    "# Проверяем модель на тестовых данных\n",
    "scores = model.evaluate_generator(test_generator, nb_test_samples // batch_size)\n",
    "print(\"Точность модели на тестовых данных: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_dir = 'ts'\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "test_generator.reset()\n",
    "predict = model.predict_generator(test_generator, steps = None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
    "for i in predict:\n",
    "    print(np.argmax(i))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
